g# Chat Proxy Backend

A proxy backend that masks API calls to the Genies chat service, handling authentication and providing a simplified API for frontend chat applications.

## Features

- Masks upstream chat API endpoints
- Handles authentication with hardcoded Bearer token (stored in environment variables)
- Session-based chat management
- CORS enabled for frontend access
- TypeScript for type safety
- Request logging and error handling

## Setup

### 1. Install Dependencies

```bash
npm install
```

### 2. Configure Environment

Copy `.env.example` to `.env` and update the AUTH_TOKEN:

```bash
cp .env.example .env
```

Edit `.env` and replace `your_bearer_token_here` with your actual Bearer token.

### 3. Run the Server

**Development mode** (with auto-reload):
```bash
npm run dev
```

**Production mode**:
```bash
npm run build
npm start
```

The server will start on `http://localhost:3000` (or the port specified in `.env`).

## API Endpoints

### Health Check
```
GET /health
```
Returns server status.

### Get Character Config
```
GET /api/config/:configId
```
Fetches the configuration for a specific character.

**Example:**
```bash
curl http://localhost:3000/api/config/CHAR_6c606003-8b02-4943-8690-73b9b8fe3ae4
```

### Create Chat Session
```
POST /api/sessions
```
Creates a new chat session for a character.

**Request body:**
```json
{
  "config_id": "CHAR_6c606003-8b02-4943-8690-73b9b8fe3ae4"
}
```

**Response:**
```json
{
  "session_id": "c62ca618-ddef-43bf-a8e4-d6268c17f965",
  "config_id": "CHAR_6c606003-8b02-4943-8690-73b9b8fe3ae4",
  "user_id": "8cae102a-1c31-4016-9ec0-cf69aabc2cc1",
  "session_status": "active",
  "updated_at": 1762311017
}
```

### Send Chat Message
```
POST /api/chat
```
Sends a message to the chat API and receives AI response.

**Request body:**
```json
{
  "session_id": "your_session_id",
  "config_id": "CHAR_6c606003-8b02-4943-8690-73b9b8fe3ae4",
  "input": "Hello, how are you?"
}
```

**Response:**
```json
{
  "ai": "I'm doing great, thanks for asking!",
  "session_id": "your_session_id",
  "request_id": "...",
  "text_response_cleaned": "I'm doing great, thanks for asking!",
  "warning_message": null
}
```

### Generate Follow-up Options
```
POST /api/followups
```
Generates 4 contextual follow-up options based on the last user message and AI response.

**Request body:**
```json
{
  "user_turn": "Hello, how are you?",
  "assistant_turn": "I'm doing great, thanks for asking! How can I help you today?"
}
```

**Response:**
```json
{
  "followups": [
    "Tell me more about yourself",
    "What can you help me with?",
    "What's your favorite topic?",
    "Do you have any recommendations?"
  ]
}
```

## Frontend Integration

> **ðŸ“– For detailed frontend session management guide, see [FRONTEND_SESSION_MANAGEMENT.md](./FRONTEND_SESSION_MANAGEMENT.md)**

### Basic Example

The backend acts as a **proxy only** - all session IDs are generated by the Genies API. The frontend must:

1. **Check for existing session** in localStorage before creating a new one
2. **Store session IDs locally** (one per character)
3. **Reuse session IDs** across page refreshes

**Quick Example:**

```javascript
// Get or create session for a character
async function getOrCreateSession(configId) {
  // Check localStorage first
  const sessionKey = `session_${configId}`;
  const existingSessionId = localStorage.getItem(sessionKey);
  
  if (existingSessionId) {
    return existingSessionId; // Reuse existing session
  }
  
  // Create new session
  const response = await fetch('http://localhost:3000/api/sessions', {
    method: 'POST',
    headers: { 'Content-Type': 'application/json' },
    body: JSON.stringify({ config_id: configId })
  });
  
  const session = await response.json();
  const sessionId = session.session_id; // Note: field is 'session_id', not 'id'
  
  // Store for future use
  localStorage.setItem(sessionKey, sessionId);
  return sessionId;
}

// Send chat message
async function sendMessage(configId, message) {
  const sessionId = await getOrCreateSession(configId);
  
  const response = await fetch('http://localhost:3000/api/chat', {
    method: 'POST',
    headers: { 'Content-Type': 'application/json' },
    body: JSON.stringify({
      session_id: sessionId,
      config_id: configId,
      input: message
    })
  });
  
  return await response.json();
}
```

See [FRONTEND_SESSION_MANAGEMENT.md](./FRONTEND_SESSION_MANAGEMENT.md) for complete examples including React components, error handling, and multi-character session management.

## Project Structure

```
chat-proxy/
â”œâ”€â”€ src/
â”‚   â”œâ”€â”€ routes/
â”‚   â”‚   â””â”€â”€ chat.ts          # API route handlers
â”‚   â”œâ”€â”€ services/
â”‚   â”‚   â””â”€â”€ chatService.ts   # Upstream API client
â”‚   â”œâ”€â”€ middleware/
â”‚   â”‚   â””â”€â”€ logger.ts        # Request logging and error handling
â”‚   â”œâ”€â”€ types/
â”‚   â”‚   â””â”€â”€ chat.ts          # TypeScript type definitions
â”‚   â””â”€â”€ index.ts             # Express server setup
â”œâ”€â”€ .env                      # Environment variables (gitignored)
â”œâ”€â”€ .env.example              # Environment template
â”œâ”€â”€ .gitignore
â”œâ”€â”€ package.json
â”œâ”€â”€ tsconfig.json
â””â”€â”€ README.md
```

## Security Notes

- The `.env` file is gitignored to prevent accidentally committing secrets
- The AUTH_TOKEN should be kept secure and not shared
- Consider adding rate limiting for production use
- CORS is currently open to all origins - customize in `src/index.ts` if needed

## Future Enhancements

- [ ] Implement automatic token refresh logic
- [ ] Add rate limiting
- [ ] Add request validation middleware
- [ ] Support for additional chat features (images, voice, etc.)
- [ ] Add comprehensive error handling for token expiration

## License

ISC
